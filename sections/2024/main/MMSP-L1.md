# ICASSP-2024-Papers

<table>
    <tr>
        <td><strong>Application</strong></td>
        <td>
            <a href="https://huggingface.co/spaces/DmitryRyumin/NewEraAI-Papers" style="float:left;">
                <img src="https://img.shields.io/badge/ðŸ¤—-NewEraAI--Papers-FFD21F.svg" alt="App" />
            </a>
        </td>
    </tr>
    <tr>
        <td><strong>Previous Collections</strong></td>
        <td>
            <a href="https://github.com/DmitryRyumin/ICASSP-2023-24-Papers/blob/main/README_2023.md">
                <img src="http://img.shields.io/badge/ICASSP-2023-0073AE.svg" alt="Conference">
            </a>
        </td>
    </tr>
</table>

<div align="center">
    <a href="https://github.com/DmitryRyumin/ICASSP-2023-24-Papers/blob/main/sections/2024/main/AASP-L2.md">
        <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/left.svg" width="40" alt="" />
    </a>
    <a href="https://github.com/DmitryRyumin/ICASSP-2023-24-Papers/">
        <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/home.svg" width="40" alt="" />
    </a>
    <a href="https://github.com/DmitryRyumin/ICASSP-2023-24-Papers/blob/main/sections/2024/main/AASP-L3.md">
        <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/right.svg" width="40" alt="" />
    </a>
</div>

## Multimodal Processing: Vision + Language

![Section Papers](https://img.shields.io/badge/Section%20Papers-12-42BA16) ![Preprint Papers](https://img.shields.io/badge/Preprint%20Papers-0-b31b1b) ![Papers with Open Code](https://img.shields.io/badge/Papers%20with%20Open%20Code-0-1D7FBF) ![Papers with Video](https://img.shields.io/badge/Papers%20with%20Video-0-FF0000)

| **Title** | **Repo** | **Paper** | **Video** |
|-----------|:--------:|:---------:|:---------:|
| A Relation-Aware Heterogeneous Graph Transformer on Dynamic Fusion for Multimodal Classification Tasks | :heavy_minus_sign: | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10446972-E4A42C.svg)](https://ieeexplore.ieee.org/document/10446972) | :heavy_minus_sign: |
| Multi-Source Dynamic Interactive Network Collaborative Reasoning Image Captioning | :heavy_minus_sign: | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10446104-E4A42C.svg)](https://ieeexplore.ieee.org/document/10446104) | :heavy_minus_sign: |
| Towards Practical and Efficient Image-to-Speech Captioning with Vision-Language Pre-Training and Multi-Modal Tokens | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://ms-dot-k.github.io/Image-to-Speech-Captioning/) <br /> [![GitHub](https://img.shields.io/github/stars/ms-dot-k/Image-to-Speech?style=flat)](https://github.com/ms-dot-k/Image-to-Speech) | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10446888-E4A42C.svg)](https://ieeexplore.ieee.org/document/10446888) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2309.08531-b31b1b.svg)](https://arxiv.org/abs/2309.08531) | :heavy_minus_sign: |
| Textual Tokens Classification for Multi-Modal Alignment in Vision-Language Tracking | :heavy_minus_sign: | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10446122-E4A42C.svg)](https://ieeexplore.ieee.org/document/10446122) | :heavy_minus_sign: |
| Caption Unification for Multi-View Lifelogging Images based on In-Context Learning with Heterogeneous Semantic Contents | :heavy_minus_sign: | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10445969-E4A42C.svg)](https://ieeexplore.ieee.org/document/10445969) | :heavy_minus_sign: |
| ControlCap: Controllable Captioning via No-Fuss Lexicon | :heavy_minus_sign: | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10447133-E4A42C.svg)](https://ieeexplore.ieee.org/document/10447133) | :heavy_minus_sign: |
| Large Language Models Augmented Rating Prediction in Recommender System | [![GitHub](https://img.shields.io/github/stars/sichunluo/LAMAR?style=flat)](https://github.com/sichunluo/LAMAR) | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10447514-E4A42C.svg)](https://ieeexplore.ieee.org/document/10447514) | :heavy_minus_sign: |
| Prompting Large Language Models with Fine-Grained Visual Relations from Scene Graph for Visual Question Answering | :heavy_minus_sign: | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10448321-E4A42C.svg)](https://ieeexplore.ieee.org/document/10448321) | :heavy_minus_sign: |
| Learning Density Regulated and Multi-View Consistent Unsigned Distance Fields | :heavy_minus_sign: | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10447163-E4A42C.svg)](https://ieeexplore.ieee.org/document/10447163) | :heavy_minus_sign: |
| Graph-based Environment Representation for Vision-and-Language Navigation in Continuous Environments | :heavy_minus_sign: | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10446850-E4A42C.svg)](https://ieeexplore.ieee.org/document/10446850) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2301.04352-b31b1b.svg)](https://arxiv.org/abs/2301.04352) | :heavy_minus_sign: |
| Human Motion Capture Data Segmentation based on ST-GCN | :heavy_minus_sign: | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10446553-E4A42C.svg)](https://ieeexplore.ieee.org/document/10446553) | :heavy_minus_sign: |
| Does Video Summarization Require Videos? Quantifying the Effectiveness of Language in Video Summarization | :heavy_minus_sign: | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10445931-E4A42C.svg)](https://ieeexplore.ieee.org/document/10445931) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2309.09405-b31b1b.svg)](https://arxiv.org/abs/2309.09405) | :heavy_minus_sign: |
