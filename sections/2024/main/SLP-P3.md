# ICASSP-2024-Papers

<table>
    <tr>
        <td><strong>Application</strong></td>
        <td>
            <a href="https://huggingface.co/spaces/DmitryRyumin/NewEraAI-Papers" style="float:left;">
                <img src="https://img.shields.io/badge/ðŸ¤—-NewEraAI--Papers-FFD21F.svg" alt="App" />
            </a>
        </td>
    </tr>
    <tr>
        <td><strong>Previous Collections</strong></td>
        <td>
            <a href="https://github.com/DmitryRyumin/ICASSP-2023-24-Papers/blob/main/README_2023.md">
                <img src="http://img.shields.io/badge/ICASSP-2023-0073AE.svg" alt="Conference">
            </a>
        </td>
    </tr>
</table>

<div align="center">
    <a href="https://github.com/DmitryRyumin/ICASSP-2023-24-Papers/blob/main/sections/2024/main/GC-L3.md">
        <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/left.svg" width="40" alt="" />
    </a>
    <a href="https://github.com/DmitryRyumin/ICASSP-2023-24-Papers/">
        <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/home.svg" width="40" alt="" />
    </a>
    <a href="https://github.com/DmitryRyumin/ICASSP-2023-24-Papers/blob/main/sections/2024/main/IVMSP-P6.md">
        <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/right.svg" width="40" alt="" />
    </a>
</div>

## Speech Enhancement and Separation

![Section Papers](https://img.shields.io/badge/Section%20Papers-30-42BA16) ![Preprint Papers](https://img.shields.io/badge/Preprint%20Papers-15-b31b1b) ![Papers with Open Code](https://img.shields.io/badge/Papers%20with%20Open%20Code-2-1D7FBF) ![Papers with Video](https://img.shields.io/badge/Papers%20with%20Video-0-FF0000)

| **Title** | **Repo** | **Paper** | **Video** |
|-----------|:--------:|:---------:|:---------:|
| Two-Step Knowledge Distillation for Tiny Speech Enhancement | :heavy_minus_sign: | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10446796-E4A42C.svg)](https://ieeexplore.ieee.org/document/10446796) <br/> [![arXiv](https://img.shields.io/badge/arXiv-2309.08144-b31b1b.svg)](https://arxiv.org/abs/2309.08144) | :heavy_minus_sign: |
| On Real-Time Multi-Stage Speech Enhancement Systems | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://meng-lingjun-xjtu.github.io/2stage/) | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10447228-E4A42C.svg)](https://ieeexplore.ieee.org/document/10447228) <br/> [![arXiv](https://img.shields.io/badge/arXiv-2312.12415-b31b1b.svg)](https://arxiv.org/abs/2312.12415) | :heavy_minus_sign: |
| An Efficient and Interpretable Speech Enhancement Network via Deep Dictionary Learning | :heavy_minus_sign: | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10447188-E4A42C.svg)](https://ieeexplore.ieee.org/document/10447188) | :heavy_minus_sign: |
| SICRN: Advancing Speech Enhancement through State Space Model and Inplace Convolution Techniques | :heavy_minus_sign: | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10446396-E4A42C.svg)](https://ieeexplore.ieee.org/document/10446396) <br/> [![arXiv](https://img.shields.io/badge/arXiv-2402.14225-b31b1b.svg)](https://arxiv.org/abs/2402.14225) | :heavy_minus_sign: |
| Lightweight Multi-Axial Transformer with Frequency Prompt for Single Channel Speech Enhancement | :heavy_minus_sign: | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10446787-E4A42C.svg)](https://ieeexplore.ieee.org/document/10446787) | :heavy_minus_sign: |
| FSPEN: An Ultra-Lightweight Network for Real Time Speech Enahncment | :heavy_minus_sign: | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10446016-E4A42C.svg)](https://ieeexplore.ieee.org/document/10446016) | :heavy_minus_sign: |
| Improving Design of Input Condition Invariant Speech Enhancement | [![GitHub](https://img.shields.io/github/stars/espnet/espnet?style=flat)](https://github.com/espnet/espnet) | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10448155-E4A42C.svg)](https://ieeexplore.ieee.org/document/10448155) <br/> [![arXiv](https://img.shields.io/badge/arXiv-2401.14271-b31b1b.svg)](https://arxiv.org/abs/2401.14271) | :heavy_minus_sign: |
| On the Importance of Neural Wiener Filter for Resource Efficient Multichannel Speech Enhancement | :heavy_minus_sign: | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10448014-E4A42C.svg)](https://ieeexplore.ieee.org/document/10448014) <br/> [![arXiv](https://img.shields.io/badge/arXiv-2401.07882-b31b1b.svg)](https://arxiv.org/abs/2401.07882) | :heavy_minus_sign: |
| Decoupled Spatial and Temporal Processing for Resource Efficient Multichannel Speech Enhancement | :heavy_minus_sign: | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10446087-E4A42C.svg)](https://ieeexplore.ieee.org/document/10446087) <br/> [![arXiv](https://img.shields.io/badge/arXiv-2401.07879-b31b1b.svg)](https://arxiv.org/abs/2401.07879) | :heavy_minus_sign: |
| Complexity Scaling for Speech Denoising | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://hangtingchen.github.io/Complexity-Scaling-for-Speech-Denoising.github.io/) | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10448061-E4A42C.svg)](https://ieeexplore.ieee.org/document/10448061) <br/> [![arXiv](https://img.shields.io/badge/arXiv-2309.07757-b31b1b.svg)](https://arxiv.org/abs/2309.07757) | :heavy_minus_sign: |
| A Two-Stage Framework in Cross-Spectrum Domain for Real-Time Speech Enhancement | [![GitHub](https://img.shields.io/github/stars/Zhangyuewei98/FDFNet?style=flat)](https://github.com/Zhangyuewei98/FDFNet) | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10447096-E4A42C.svg)](https://ieeexplore.ieee.org/document/10447096) <br/> [![arXiv](https://img.shields.io/badge/arXiv-2401.10494-b31b1b.svg)](https://arxiv.org/abs/2401.10494) | :heavy_minus_sign: |
| Hierarchical Speaker Representation for Target Speaker Extraction | :heavy_minus_sign: | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10447755-E4A42C.svg)](https://ieeexplore.ieee.org/document/10447755) <br/> [![arXiv](https://img.shields.io/badge/arXiv-2210.15849-b31b1b.svg)](https://arxiv.org/abs/2210.15849) | :heavy_minus_sign: |
| Target Speaker Extraction by Directly Exploiting Contextual Information in the Time-Frequency Domain | :heavy_minus_sign: | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10447529-E4A42C.svg)](https://ieeexplore.ieee.org/document/10447529) <br/> [![arXiv](https://img.shields.io/badge/arXiv-2402.17146-b31b1b.svg)](https://arxiv.org/abs/2402.17146) | :heavy_minus_sign: |
| Curricular Contrastive Regularization for Speech Enhancement with Self-Supervised Representations | :heavy_minus_sign: | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10445912-E4A42C.svg)](https://ieeexplore.ieee.org/document/10445912) | :heavy_minus_sign: |
| Employing Real Training Data for Deep Noise Suppression | :heavy_minus_sign: | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10448333-E4A42C.svg)](https://ieeexplore.ieee.org/document/10448333) <br/> [![arXiv](https://img.shields.io/badge/arXiv-2309.02432-b31b1b.svg)](https://arxiv.org/abs/2309.02432) | :heavy_minus_sign: |
| Leveraging Self-Supervised Speech Representations for Domain Adaptation in Speech Enhancement | :heavy_minus_sign: | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10447573-E4A42C.svg)](https://ieeexplore.ieee.org/document/10447573) | :heavy_minus_sign: |
| Neural Network-based Virtual Microphone Estimation with Virtual Microphone and Beamformer-Level Multi-Task Loss | :heavy_minus_sign: | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10446139-E4A42C.svg)](https://ieeexplore.ieee.org/document/10446139) <br/> [![arXiv](https://img.shields.io/badge/arXiv-2311.11595-b31b1b.svg)](https://arxiv.org/abs/2311.11595) | :heavy_minus_sign: |
| Opine: Leveraging a Optimization-Inspired Deep Unfolding Method for Multi-Channel Speech Enhancement | :heavy_minus_sign: | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10447369-E4A42C.svg)](https://ieeexplore.ieee.org/document/10447369) | :heavy_minus_sign: |
| SELM: Speech Enhancement using Discrete Tokens and Language Models | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://honee-w.github.io/SELM/) | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10447464-E4A42C.svg)](https://ieeexplore.ieee.org/document/10447464) <br/> [![arXiv](https://img.shields.io/badge/arXiv-2312.09747-b31b1b.svg)](https://arxiv.org/abs/2312.09747) | :heavy_minus_sign: |
| SECP: A Speech Enhancement-based Curation Pipeline for Scalable Acquisition of Clean Speech | :heavy_minus_sign: | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10446973-E4A42C.svg)](https://ieeexplore.ieee.org/document/10446973) <br/> [![arXiv](https://img.shields.io/badge/arXiv-2402.12482-b31b1b.svg)](https://arxiv.org/abs/2402.12482) | :heavy_minus_sign: |
| Attention-Driven Multichannel Speech Enhancement in Moving Sound Source Scenarios | :heavy_minus_sign: | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10448177-E4A42C.svg)](https://ieeexplore.ieee.org/document/10448177) <br/> [![arXiv](https://img.shields.io/badge/arXiv-2312.10756-b31b1b.svg)](https://arxiv.org/abs/2312.10756) | :heavy_minus_sign: |
| How does End-to-End Speech Recognition Training Impact Speech Enhancement Artifacts? | :heavy_minus_sign: | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10447750-E4A42C.svg)](https://ieeexplore.ieee.org/document/10447750) <br/> [![arXiv](https://img.shields.io/badge/arXiv-2311.11599-b31b1b.svg)](https://arxiv.org/abs/2311.11599) | :heavy_minus_sign: |
| An End-to-End EEG Channel Selection Method with Residual Gumbel Softmax for Brain-Assisted Speech Enhancement | :heavy_minus_sign: | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10446263-E4A42C.svg)](https://ieeexplore.ieee.org/document/10446263) | :heavy_minus_sign: |
| MossFormer2: Combining Transformer and RNN-Free Recurrent Network for Enhanced Time-Domain Monaural Speech Separation | [![GitHub](https://img.shields.io/github/stars/alibabasglab/MossFormer2?style=flat)](https://github.com/alibabasglab/MossFormer2) | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10445985-E4A42C.svg)](https://ieeexplore.ieee.org/document/10445985) <br/> [![arXiv](https://img.shields.io/badge/arXiv-2312.11825-b31b1b.svg)](https://arxiv.org/abs/2312.11825) | :heavy_minus_sign: |
| What do Neural Networks Listen to? Exploring the Crucial Bands in Speech Enhancement using SINC-Convolution | :heavy_minus_sign: | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10445878-E4A42C.svg)](https://ieeexplore.ieee.org/document/10445878) <br/> [![arXiv](https://img.shields.io/badge/arXiv-2403.01785-b31b1b.svg)](https://arxiv.org/abs/2403.01785) | :heavy_minus_sign: |
| Hybrid Attention Time-Frequency Analysis Network for Single-Channel Speech Enhancement | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://xingweiliang.github.io/HATFANet.html) | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10445944-E4A42C.svg)](https://ieeexplore.ieee.org/document/10445944) | :heavy_minus_sign: |
| Speaker Adaptation for Enhancement of Bone-Conducted Speech |  | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10446294-E4A42C.svg)](https://ieeexplore.ieee.org/document/10446294) | :heavy_minus_sign: |
| A Weighted-Variance Variational Autoencoder Model for Speech Enhancement |  | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10448177-E4A42C.svg)](https://ieeexplore.ieee.org/document/10448177) | :heavy_minus_sign: |
| Posterior Sampling Algorithms for Unsupervised Speech Enhancement with Recurrent Variational Autoencoder |  | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10447837-E4A42C.svg)](https://ieeexplore.ieee.org/document/10447837) | :heavy_minus_sign: |
| A Separation Priority Pipeline for Single-Channel Speech Separation in Noisy Environments |  | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10448116-E4A42C.svg)](https://ieeexplore.ieee.org/document/10448116) | :heavy_minus_sign: |
