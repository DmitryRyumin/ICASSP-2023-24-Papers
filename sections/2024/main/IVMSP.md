# ICASSP-2024-Papers

<table>
    <tr>
        <td><strong>Application</strong></td>
        <td>
            <a href="https://huggingface.co/spaces/DmitryRyumin/NewEraAI-Papers" style="float:left;">
                <img src="https://img.shields.io/badge/ðŸ¤—-NewEraAI--Papers-FFD21F.svg" alt="App" />
            </a>
        </td>
    </tr>
    <tr>
        <td><strong>Previous Collections</strong></td>
        <td>
            <a href="https://github.com/DmitryRyumin/ICASSP-2023-24-Papers/blob/main/README_2023.md">
                <img src="http://img.shields.io/badge/ICASSP-2023-0073AE.svg" alt="Conference">
            </a>
        </td>
    </tr>
</table>

<div align="center">
    <a href="https://github.com/DmitryRyumin/ICASSP-2023-24-Papers/blob/main/sections/2024/main/MMSP.md">
        <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/left.svg" width="40" alt="" />
    </a>
    <a href="https://github.com/DmitryRyumin/ICASSP-2023-24-Papers/">
        <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/home.svg" width="40" alt="" />
    </a>
    <a href="https://github.com/DmitryRyumin/ICASSP-2023-24-Papers/blob/main/sections/2024/main/AASP.md">
        <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/right.svg" width="40" alt="" />
    </a>
</div>

## Vision and Language

![Section Papers](https://img.shields.io/badge/Section%20Papers-18-42BA16) ![Preprint Papers](https://img.shields.io/badge/Preprint%20Papers-3-b31b1b) ![Papers with Open Code](https://img.shields.io/badge/Papers%20with%20Open%20Code-3-1D7FBF) ![Papers with Video](https://img.shields.io/badge/Papers%20with%20Video-0-FF0000)

| **Title** | **Repo** | **Paper** | **Video** |
|-----------|:--------:|:---------:|:---------:|
| JM-CLIP: A Joint Modal Similarity Contrastive Learning Model for Video-Text Retrieval | [![GitHub](https://img.shields.io/github/stars/DannielGe/JM-CLIP?style=flat)](https://github.com/DannielGe/JM-CLIP) | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10446490-E4A42C.svg)](https://ieeexplore.ieee.org/document/10446490) | :heavy_minus_sign: |
| Language-Free Compositional Action Generation via Decoupling Refinement | [![GitHub](https://img.shields.io/github/stars/XLiu443/Language-free-Compositional-Action-Generation-via-Decoupling-Refinement?style=flat)](https://github.com/XLiu443/Language-free-Compositional-Action-Generation-via-Decoupling-Refinement) | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10448207-E4A42C.svg)](https://ieeexplore.ieee.org/document/10448207) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2307.03538-b31b1b.svg)](https://arxiv.org/abs/2307.03538) | :heavy_minus_sign: |
| DAP: Domain-Aware Prompt Learning for Vision-and-Language Navigation | :heavy_minus_sign: | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10446504-E4A42C.svg)](https://ieeexplore.ieee.org/document/10446504) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2311.17812-b31b1b.svg)](https://arxiv.org/abs/2311.17812) | :heavy_minus_sign: |
| M3sum: A Novel Unsupervised Language-Guided Video Summarization | [![GitHub](https://img.shields.io/github/stars/ZovanZhou/M3Sum?style=flat)](https://github.com/ZovanZhou/M3Sum) | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10447504-E4A42C.svg)](https://ieeexplore.ieee.org/document/10447504) | :heavy_minus_sign: |
| WAVER: Writing-Style Agnostic Text-Video Retrieval via Distilling Vision-Language Models through Open-Vocabulary Knowledge | :heavy_minus_sign: | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10446193-E4A42C.svg)](https://ieeexplore.ieee.org/document/10446193) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2312.09507-b31b1b.svg)](https://arxiv.org/abs/2312.09507) | :heavy_minus_sign: |
| MTIDNet: A Multimodal Temporal Interest Detection Network for Video Summarization | :heavy_minus_sign: | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10448236-E4A42C.svg)](https://ieeexplore.ieee.org/document/10448236) | :heavy_minus_sign: |
| Human Guided Cross-Modal Reasoning with Semantic Attention Learning for Visual Question Answering | :heavy_minus_sign: | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10448302-E4A42C.svg)](https://ieeexplore.ieee.org/document/10448302) | :heavy_minus_sign: |
| Semanticmapper: Region-Specific Domain Adaptation for 3D Shapes Through Lexical Delineation | :heavy_minus_sign: | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10446758-E4A42C.svg)](https://ieeexplore.ieee.org/document/10446758) | :heavy_minus_sign: |
| Self-Distilled Dynamic Fusion Network for Language-based Fashion Retrieval | :heavy_minus_sign: | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10445903-E4A42C.svg)](https://ieeexplore.ieee.org/document/10445903) | :heavy_minus_sign: |
| Implicit-Knowledge-Guided Align Before Understanding for KB-VQA | :heavy_minus_sign: | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10448108-E4A42C.svg)](https://ieeexplore.ieee.org/document/10448108) | :heavy_minus_sign: |
| Imitating the Human Visual System for Scanpath Predicting | :heavy_minus_sign: | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10447354-E4A42C.svg)](https://ieeexplore.ieee.org/document/10447354) | :heavy_minus_sign: |
| Read, Spell and Repeat: Scene Text Recognition with Vision-Language Circular Refinement | :heavy_minus_sign: | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10446176-E4A42C.svg)](https://ieeexplore.ieee.org/document/10446176) | :heavy_minus_sign: |
| End-to-End Spatially-Constrained Multi-Perspective Fine-Grained Image Captioning | :heavy_minus_sign: | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10445846-E4A42C.svg)](https://ieeexplore.ieee.org/document/10445846) | :heavy_minus_sign: |
| Improved Image Captioning via Knowledge Graph-Augmented Models | :heavy_minus_sign: | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10447637-E4A42C.svg)](https://ieeexplore.ieee.org/document/10447637) | :heavy_minus_sign: |
| Think as People: Context-Driven Multi-Image News Captioning with Adaptive Dual Attention | :heavy_minus_sign: | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10446024-E4A42C.svg)](https://ieeexplore.ieee.org/document/10446024) | :heavy_minus_sign: |
| MGRL: Mutual-Guidance Representation Learning for Text-to-Image Person Retrieval | :heavy_minus_sign: | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10447260-E4A42C.svg)](https://ieeexplore.ieee.org/document/10447260) | :heavy_minus_sign: |
| Fine-Grained Features Alignment and Fusion for Text-Video Cross-Modal Retrieval | :heavy_minus_sign: | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10446511-E4A42C.svg)](https://ieeexplore.ieee.org/document/10446511) | :heavy_minus_sign: |
| Label Correction for Sketch-based 3d Shape Retrieval | :heavy_minus_sign: | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10447927-E4A42C.svg)](https://ieeexplore.ieee.org/document/10447927) | :heavy_minus_sign: |
| Glocal Cascading Network for Topic Enhanced Visual Storytelling | :heavy_minus_sign: | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10447361-E4A42C.svg)](https://ieeexplore.ieee.org/document/10447361) | :heavy_minus_sign: |
| CROCFUN: Cross-Modal Conditional Fusion Network for Pansharpening | :heavy_minus_sign: | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10446470-E4A42C.svg)](https://ieeexplore.ieee.org/document/10446470) | :heavy_minus_sign: |
| Domain-Wise Invariant Learning for Panoptic Scene Graph Generation | :heavy_minus_sign: | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10447193-E4A42C.svg)](https://ieeexplore.ieee.org/document/10447193) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2310.05867-b31b1b.svg)](https://arxiv.org/abs/2310.05867) | :heavy_minus_sign: |
| CReStyler: Text-Guided Single Image Style Transfer Method based on CNN and Restormer | :heavy_minus_sign: | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10446192-E4A42C.svg)](https://ieeexplore.ieee.org/document/10446192) | :heavy_minus_sign: |
| Maskstr: Guide Scene Text Recognition Models with Masking | :heavy_minus_sign: | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10446874-E4A42C.svg)](https://ieeexplore.ieee.org/document/10446874) | :heavy_minus_sign: |
| Supplementing Missing Visions via Dialog for Scene Graph Generations | [![GitHub](https://img.shields.io/github/stars/L-YeZhu/SI-Dial?style=flat)](https://github.com/L-YeZhu/SI-Dial) | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10446239-E4A42C.svg)](https://ieeexplore.ieee.org/document/10446239) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2204.11143-b31b1b.svg)](https://arxiv.org/abs/2204.11143) | :heavy_minus_sign: |
| CKT-RCM: Clip-based Knowledge Transfer and Relational Context Mining for Unbiased Panoptic Scene Graph Generation | :heavy_minus_sign: | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10446810-E4A42C.svg)](https://ieeexplore.ieee.org/document/10446810) | :heavy_minus_sign: |
| Memory Self-Calibrated Network for Visual Grounding | :heavy_minus_sign: | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10447732-E4A42C.svg)](https://ieeexplore.ieee.org/document/10447732) | :heavy_minus_sign: |
| Text-Video Completion Networks with Motion Compensation and Attention Aggregation | :heavy_minus_sign: | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10447901-E4A42C.svg)](https://ieeexplore.ieee.org/document/10447901) | :heavy_minus_sign: |
| M2SUM: Multi-Granularity Scale-Adaptive Video Summarizer towards Informative Context Representation Learning | :heavy_minus_sign: | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10446527-E4A42C.svg)](https://ieeexplore.ieee.org/document/10446527) | :heavy_minus_sign: |
| Template-Guided Data Augmentation for Unbiased Scene Graph Generation | :heavy_minus_sign: | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10448033-E4A42C.svg)](https://ieeexplore.ieee.org/document/10448033) | :heavy_minus_sign: |
<!-- | TolerantGAN: Text-Guided Image Manipulation Tolerant to Real-World Image | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: | -->
