# ICASSP-2024-Papers

<table>
    <tr>
        <td><strong>Application</strong></td>
        <td>
            <a href="https://huggingface.co/spaces/DmitryRyumin/NewEraAI-Papers" style="float:left;">
                <img src="https://img.shields.io/badge/ðŸ¤—-NewEraAI--Papers-FFD21F.svg" alt="App" />
            </a>
        </td>
    </tr>
    <tr>
        <td><strong>Previous Collections</strong></td>
        <td>
            <a href="https://github.com/DmitryRyumin/ICASSP-2023-24-Papers/blob/main/README_2023.md">
                <img src="http://img.shields.io/badge/ICASSP-2023-0073AE.svg" alt="Conference">
            </a>
        </td>
    </tr>
</table>

<div align="center">
    <a href="https://github.com/DmitryRyumin/ICASSP-2023-24-Papers/blob/main/sections/2024/main/SLP-L10.md">
        <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/left.svg" width="40" alt="" />
    </a>
    <a href="https://github.com/DmitryRyumin/ICASSP-2023-24-Papers/">
        <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/home.svg" width="40" alt="" />
    </a>
    <a href="https://github.com/DmitryRyumin/ICASSP-2023-24-Papers/blob/main/sections/2024/main/SLP-L11.md">
        <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/right.svg" width="40" alt="" />
    </a>
</div>

## Adversarial Machine Learning

![Section Papers](https://img.shields.io/badge/Section%20Papers-32-42BA16) ![Preprint Papers](https://img.shields.io/badge/Preprint%20Papers-14-b31b1b) ![Papers with Open Code](https://img.shields.io/badge/Papers%20with%20Open%20Code-6-1D7FBF) ![Papers with Video](https://img.shields.io/badge/Papers%20with%20Video-0-FF0000)

| **Title** | **Repo** | **Paper** | **Video** |
|-----------|:--------:|:---------:|:---------:|
| Defending Against Clean-Image Backdoor Attack in Multi-Label Classification | :heavy_minus_sign: | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10447895-E4A42C.svg)](https://ieeexplore.ieee.org/document/10447895) | :heavy_minus_sign: |
| Robustness Against Adversarial Attacks via Learning Confined Adversarial Polytopes | :heavy_minus_sign: | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10446776-E4A42C.svg)](https://ieeexplore.ieee.org/document/10446776) <br/> [![arXiv](https://img.shields.io/badge/arXiv-2401.07991-b31b1b.svg)](https://arxiv.org/abs/2401.07991) | :heavy_minus_sign: |
| SSTA: Salient Spatially Transformed Attack | :heavy_minus_sign: | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10447882-E4A42C.svg)](https://ieeexplore.ieee.org/document/10447882) <br/> [![arXiv](https://img.shields.io/badge/arXiv-2312.07258-b31b1b.svg)](https://arxiv.org/abs/2312.07258) | :heavy_minus_sign: |
| Enhancing Adversarial Transferability in Object Detection with Bidirectional Feature Distortion | :heavy_minus_sign: | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10447293-E4A42C.svg)](https://ieeexplore.ieee.org/document/10447293) | :heavy_minus_sign: |
| GCIA: A Black-Box Graph Injection Attack Method via Graph Contrastive Learning | [![GitHub](https://img.shields.io/github/stars/Gmrider13/GCIA?style=flat)](https://github.com/Gmrider13/GCIA) | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10446876-E4A42C.svg)](https://ieeexplore.ieee.org/document/10446876) | :heavy_minus_sign: |
| Towards a Unified View of Adversarial Training: A Contrastive Perspective | :heavy_minus_sign: | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10446746-E4A42C.svg)](https://ieeexplore.ieee.org/document/10446746) | :heavy_minus_sign: |
| MEAT: Median-Ensemble Adversarial Training for Improving Robustness and Generalization | :heavy_minus_sign: | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10446117-E4A42C.svg)](https://ieeexplore.ieee.org/document/10446117) <br/> [![arXiv](https://img.shields.io/badge/arXiv-2406.14259-b31b1b.svg)](https://arxiv.org/abs/2406.14259) | :heavy_minus_sign: |
| Architecture-Agnostic Iterative Black-Box Certified Defense Against Adversarial Patches | :heavy_minus_sign: | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10448145-E4A42C.svg)](https://ieeexplore.ieee.org/document/10448145) <br/> [![arXiv](https://img.shields.io/badge/arXiv-2305.10929-b31b1b.svg)](https://arxiv.org/abs/2305.10929) | :heavy_minus_sign: |
| OADAS: Optimizing Global Perturbation Attacks with Dual-Path Attribution Synergy | :heavy_minus_sign: | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10446681-E4A42C.svg)](https://ieeexplore.ieee.org/document/10446681) | :heavy_minus_sign: |
| Towards Video-Text Retrieval Adversarial Attack | :heavy_minus_sign: | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10448358-E4A42C.svg)](https://ieeexplore.ieee.org/document/10448358) | :heavy_minus_sign: |
| FIBA: Federated Invisible Backdoor Attack | :heavy_minus_sign: | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10446910-E4A42C.svg)](https://ieeexplore.ieee.org/document/10446910) | :heavy_minus_sign: |
| Identifying Attack-Specific Signatures in Adversarial Examples | [![GitHub](https://img.shields.io/github/stars/hsouri/REDRL?style=flat)](https://github.com/hsouri/REDRL) | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10446989-E4A42C.svg)](https://ieeexplore.ieee.org/document/10446989) <br/> [![arXiv](https://img.shields.io/badge/arXiv-2110.06802-b31b1b.svg)](https://arxiv.org/abs/2110.06802) | :heavy_minus_sign: |
| Ten-Guard: Tensor Decomposition for Backdoor Attack Detection in Deep Neural Networks | :heavy_minus_sign: | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10448222-E4A42C.svg)](https://ieeexplore.ieee.org/document/10448222) <br/> [![arXiv](https://img.shields.io/badge/arXiv-2401.05432-b31b1b.svg)](https://arxiv.org/abs/2401.05432) | :heavy_minus_sign: |
| Language Guided Adversarial Purification | [![GitHub](https://img.shields.io/github/stars/Visual-Conception-Group/LGAP?style=flat)](https://github.com/Visual-Conception-Group/LGAP) | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10446676-E4A42C.svg)](https://ieeexplore.ieee.org/document/10446676) <br/> [![arXiv](https://img.shields.io/badge/arXiv-2309.10348-b31b1b.svg)](https://arxiv.org/abs/2309.10348) | :heavy_minus_sign: |
| Image Mixing and Gradient Smoothing to Enhance the SAR Image Attack Transferability | [![GitHub](https://img.shields.io/github/stars/JHL-HUST/IMGS?style=flat)](https://github.com/JHL-HUST/IMGS) | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10448395-E4A42C.svg)](https://ieeexplore.ieee.org/document/10448395) | :heavy_minus_sign: |
| PoisonPrompt: Backdoor Attack on Prompt-based Large Language Models | :heavy_minus_sign: | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10446267-E4A42C.svg)](https://ieeexplore.ieee.org/document/10446267) <br/> [![arXiv](https://img.shields.io/badge/arXiv-2310.12439-b31b1b.svg)](https://arxiv.org/abs/2310.12439) | :heavy_minus_sign: |
| Enhancing Targeted Transferability via Feature Space Fine-Tuning | [![GitHub](https://img.shields.io/github/stars/zengh5/TA_feature_FT?style=flat)](https://github.com/zengh5/TA_feature_FT) | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10446654-E4A42C.svg)](https://ieeexplore.ieee.org/document/10446654) <br/> [![arXiv](https://img.shields.io/badge/arXiv-2401.02727-b31b1b.svg)](https://arxiv.org/abs/2401.02727) | :heavy_minus_sign: |
| Delving Deeper Into Vulnerable Samples in Adversarial Training | :heavy_minus_sign: | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10447217-E4A42C.svg)](https://ieeexplore.ieee.org/document/10447217) | :heavy_minus_sign: |
| Synthesizing Black-Box Anti-Forensics Deepfakes with High Visual Quality | :heavy_minus_sign: | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10447611-E4A42C.svg)](https://ieeexplore.ieee.org/document/10447611) <br/> [![arXiv](https://img.shields.io/badge/arXiv-2312.10713-b31b1b.svg)](https://arxiv.org/abs/2312.10713) | :heavy_minus_sign: |
| Attribution-based Scanline Perturbation Attack on 3d Detectors of Lidar Point Clouds | :heavy_minus_sign: | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10447340-E4A42C.svg)](https://ieeexplore.ieee.org/document/10447340) | :heavy_minus_sign: |
| CNFA: Conditional Normalizing Flow for Query-Limited Attack | :heavy_minus_sign: | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10447629-E4A42C.svg)](https://ieeexplore.ieee.org/document/10447629) | :heavy_minus_sign: |
| Enhancing Adversarial Robustness of DNNS via Weight Decorrelation in Training | :heavy_minus_sign: | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10447737-E4A42C.svg)](https://ieeexplore.ieee.org/document/10447737) | :heavy_minus_sign: |
| Scalable Ensemble-based Detection Method Against Adversarial Attacks for Speaker Verification | :heavy_minus_sign: | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10447441-E4A42C.svg)](https://ieeexplore.ieee.org/document/10447441) <br/> [![arXiv](https://img.shields.io/badge/arXiv-2312.08622-b31b1b.svg)](https://arxiv.org/abs/2312.08622) | :heavy_minus_sign: |
| Poisoning-Free Defense Against Black-Box Model Extraction | [![GitHub](https://img.shields.io/github/stars/Hatins/AdvFT?style=flat)](https://github.com/Hatins/AdvFT) | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10447550-E4A42C.svg)](https://ieeexplore.ieee.org/document/10447550) | :heavy_minus_sign: |
| Universal Adversarial Attack Against Speaker Recognition Models | :heavy_minus_sign: | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10447073-E4A42C.svg)](https://ieeexplore.ieee.org/document/10447073) | :heavy_minus_sign: |
| Domain Adaptive Graph Classification | :heavy_minus_sign: | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10448226-E4A42C.svg)](https://ieeexplore.ieee.org/document/10448226) <br/> [![arXiv](https://img.shields.io/badge/arXiv-2312.13536-b31b1b.svg)](https://arxiv.org/abs/2312.13536) | :heavy_minus_sign: |
| AdvTTS: Adversarial Text-to-Speech Synthesis Attack on Speaker Identification Systems | :heavy_minus_sign: | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10447190-E4A42C.svg)](https://ieeexplore.ieee.org/document/10447190) | :heavy_minus_sign: |
| NWS: Natural Textual Backdoor Attacks via Word Substitution | :heavy_minus_sign: | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10447968-E4A42C.svg)](https://ieeexplore.ieee.org/document/10447968) | :heavy_minus_sign: |
| An Initial Investigation of Neural Replay Simulator for Over-the-Air Adversarial Perturbations to Automatic Speaker Verification | :heavy_minus_sign: | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10447811-E4A42C.svg)](https://ieeexplore.ieee.org/document/10447811) <br/> [![arXiv](https://img.shields.io/badge/arXiv-2310.05354-b31b1b.svg)](https://arxiv.org/abs/2310.05354) | :heavy_minus_sign: |
| Cost Aware Untargeted Poisoning Attack Against Graph Neural Networks | :heavy_minus_sign: | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10446170-E4A42C.svg)](https://ieeexplore.ieee.org/document/10446170) <br/> [![arXiv](https://img.shields.io/badge/arXiv-2312.07158-b31b1b.svg)](https://arxiv.org/abs/2312.07158) | :heavy_minus_sign: |
| Improving Visual Quality and Transferability of Adversarial Attacks on Face Recognition Simultaneously with Adversarial Restoration | :heavy_minus_sign: | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10447402-E4A42C.svg)](https://ieeexplore.ieee.org/document/10447402) <br/> [![arXiv](https://img.shields.io/badge/arXiv-2309.01582-b31b1b.svg)](https://arxiv.org/abs/2309.01582) | :heavy_minus_sign: |
| Boosting Adversarial Robustness Distillation via Hybrid Decomposed Knowledge | :heavy_minus_sign: | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10447411-E4A42C.svg)](https://ieeexplore.ieee.org/document/10447411) | :heavy_minus_sign: |
